{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All Imports\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the file which contains the 10000 random citations\n",
    "selected_citations = pd.read_csv('selected_citations_for_evaluation_10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_list</th>\n",
       "      <th>citation_title</th>\n",
       "      <th>citation</th>\n",
       "      <th>page_title</th>\n",
       "      <th>id_list</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>['Friedrich B', 'Feng Y', 'Cohen P', 'Risler T...</td>\n",
       "      <td>The serine/threonine kinases SGK2 and SGK3 are...</td>\n",
       "      <td>Map(Title -&gt; The serine/threonine kinases SGK2...</td>\n",
       "      <td>SGK2</td>\n",
       "      <td>[['PMID', '12632189'], ['DOI', '10.1007/s00424...</td>\n",
       "      <td>10.1007/s00424-002-0993-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>['Scherer Stephen', 'Cheung J', 'MacDonald JR'...</td>\n",
       "      <td>Human Chromosome 7: DNA Sequence and Biology</td>\n",
       "      <td>Map(Title -&gt; Human Chromosome 7: DNA Sequence ...</td>\n",
       "      <td>Ectrodactyly</td>\n",
       "      <td>[['PMID', '12690205'], ['PMC', '2882961'], ['D...</td>\n",
       "      <td>10.1126/science.1083423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>['Kuiper GG', 'Carlsson B', 'Grandien K', 'Enm...</td>\n",
       "      <td>Comparison of the ligand binding specificity a...</td>\n",
       "      <td>Map(Title -&gt; Comparison of the ligand binding ...</td>\n",
       "      <td>Androstenedione</td>\n",
       "      <td>[['PMID', '9048584'], ['DOI', '10.1210/endo.13...</td>\n",
       "      <td>10.1210/endo.138.3.4979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>['Makepeace Tsao']</td>\n",
       "      <td>A New Synthesis of Mescaline</td>\n",
       "      <td>Map(Title -&gt; A New Synthesis of Mescaline, Vol...</td>\n",
       "      <td>Mescaline</td>\n",
       "      <td>[['DOI', '10.1021/ja01155a562']]</td>\n",
       "      <td>10.1021/ja01155a562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>['Rennie David']</td>\n",
       "      <td>Two Thoughts on Abraham Maslow.</td>\n",
       "      <td>Map(Title -&gt; Two Thoughts on Abraham Maslow., ...</td>\n",
       "      <td>Abraham Maslow</td>\n",
       "      <td>[['DOI', '10.1177/0022167808320537']]</td>\n",
       "      <td>10.1177/0022167808320537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        authors_list  \\\n",
       "0  ['Friedrich B', 'Feng Y', 'Cohen P', 'Risler T...   \n",
       "1  ['Scherer Stephen', 'Cheung J', 'MacDonald JR'...   \n",
       "2  ['Kuiper GG', 'Carlsson B', 'Grandien K', 'Enm...   \n",
       "3                                 ['Makepeace Tsao']   \n",
       "4                                   ['Rennie David']   \n",
       "\n",
       "                                      citation_title  \\\n",
       "0  The serine/threonine kinases SGK2 and SGK3 are...   \n",
       "1       Human Chromosome 7: DNA Sequence and Biology   \n",
       "2  Comparison of the ligand binding specificity a...   \n",
       "3                       A New Synthesis of Mescaline   \n",
       "4                    Two Thoughts on Abraham Maslow.   \n",
       "\n",
       "                                            citation       page_title  \\\n",
       "0  Map(Title -> The serine/threonine kinases SGK2...             SGK2   \n",
       "1  Map(Title -> Human Chromosome 7: DNA Sequence ...     Ectrodactyly   \n",
       "2  Map(Title -> Comparison of the ligand binding ...  Androstenedione   \n",
       "3  Map(Title -> A New Synthesis of Mescaline, Vol...        Mescaline   \n",
       "4  Map(Title -> Two Thoughts on Abraham Maslow., ...   Abraham Maslow   \n",
       "\n",
       "                                             id_list  \\\n",
       "0  [['PMID', '12632189'], ['DOI', '10.1007/s00424...   \n",
       "1  [['PMID', '12690205'], ['PMC', '2882961'], ['D...   \n",
       "2  [['PMID', '9048584'], ['DOI', '10.1210/endo.13...   \n",
       "3                   [['DOI', '10.1021/ja01155a562']]   \n",
       "4              [['DOI', '10.1177/0022167808320537']]   \n",
       "\n",
       "                         DOI  \n",
       "0  10.1007/s00424-002-0993-8  \n",
       "1    10.1126/science.1083423  \n",
       "2    10.1210/endo.138.3.4979  \n",
       "3        10.1021/ja01155a562  \n",
       "4   10.1177/0022167808320537  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading the file which contains 10000 citations which are random in nature\n",
    "selected_citations.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
    "selected_citations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total citations: 10000 and number with unique title: 9707\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Number of total citations: {} and number with unique title: {}'.format(\n",
    "        selected_citations.shape[0], selected_citations['citation_title'].nunique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the author and title for each of the unique random citations we have\n",
    "def get_params(dataset):\n",
    "    params = []\n",
    "    for i in range(dataset.shape[0]):\n",
    "        r_dict = dict()\n",
    "        title_ = dataset.iloc[i]['citation_title']\n",
    "        r_dict['query.bibliographic'] = title_\n",
    "        author = ast.literal_eval(dataset.iloc[i]['authors_list'])[0]\n",
    "        if author != 'No authors':\n",
    "            r_dict['query.author'] = author\n",
    "            r_dict['DOI'] = dataset.iloc[i]['DOI']\n",
    "            params.append(r_dict)\n",
    "\n",
    "    print('Constructed parameters for requests')\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed parameters for requests\n",
      "Total number of unique params: 9764\n"
     ]
    }
   ],
   "source": [
    "params = get_params(selected_citations)\n",
    "print('Total number of unique params: {}'.format(len(params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all the indices and shuffle them \n",
    "indices = np.arange(len(params))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a train and test split for checking which heuristic is the best heuristic\n",
    "SPLIT_THRESHOLD = (len(params) * 80) // 100\n",
    " \n",
    "training_indices = indices[:SPLIT_THRESHOLD]\n",
    "testing_indices = indices[SPLIT_THRESHOLD:]\n",
    "\n",
    "training_content = [j for i, j in enumerate(params) if i in training_indices]\n",
    "training_dois = [i['DOI'] for i in training_content]\n",
    "testing_content  = [j for i, j in enumerate(params) if i in testing_indices]\n",
    "testing_dois = [i['DOI'] for i in testing_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## taking in the column of score as the threshold and putting title, author, and DOI in dataframe\n",
    "def get_eval(score_number, training=True):\n",
    "    \n",
    "    indices__, dois__ = None, None\n",
    "    if training:\n",
    "        indices__, dois__ = training_indices, training_dois\n",
    "    else:\n",
    "        indices__, dois__ = testing_indices, testing_dois\n",
    "        \n",
    "    crossref_invalid = 0 ## Requests which are not present in CrossRef for some reason\n",
    "    no_result_for_heuristic = 0\n",
    "    \n",
    "    info_threshold = []\n",
    "    for i in tqdm_notebook(range(len(indices__))):\n",
    "        \n",
    "        \n",
    "        with open('lookup_eval/result_{}.txt'.format(indices__[i])) as f:\n",
    "            file_content = json.loads(f.read())\n",
    "        \n",
    "        if 'items' not in file_content['message'] or len(file_content['message']['items']) == 0:\n",
    "            crossref_invalid += 1\n",
    "            continue\n",
    "\n",
    "        if len(file_content['message']['items']) <= score_number:\n",
    "            no_result_for_heuristic += 1\n",
    "            continue\n",
    "            \n",
    "        res = file_content['message']['items'][score_number] ## score_number represents the threshold\n",
    "        res_doi = res.get('DOI', 'No DOI')\n",
    "        res_title = res.get('title', ['No title'])[0]\n",
    "        info_threshold.append([res_doi, res_title])\n",
    "\n",
    "\n",
    "    take_score = pd.DataFrame(info_threshold)\n",
    "    take_score.rename({0: 'ID', 1: 'title'}, axis=1, inplace=True)\n",
    "\n",
    "    present = []\n",
    "    not_present = []\n",
    "    for i in list(take_score['ID']):\n",
    "        if i in dois__:\n",
    "            present.append(i)\n",
    "        else:\n",
    "            not_present.append(i)\n",
    "    print('Total number of retreieved IDs present in original: {}'.format(len(present)))\n",
    "    print('Total number of retreieved IDs NOT present in original: {}'.format(len(not_present)))\n",
    "    print('Total number of IDs for which CrossRef request is not valid: {}'.format(crossref_invalid))\n",
    "    print('Total number of IDs for which there is no result for that heuristic: {}'.format(no_result_for_heuristic))\n",
    "    return present, not_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d12519a7974f149ad548266acc096c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7811), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of retreieved IDs present in original: 5258\n",
      "Total number of retreieved IDs NOT present in original: 2510\n",
      "Total number of IDs for which CrossRef request is not valid: 43\n",
      "Total number of IDs for which there is no result for that heuristic: 0\n"
     ]
    }
   ],
   "source": [
    "present_first_score, not_present_first_score = get_eval(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8537da5e19ab4af9afe7e1db61163bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7811), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of retreieved IDs present in original: 345\n",
      "Total number of retreieved IDs NOT present in original: 7407\n",
      "Total number of IDs for which CrossRef request is not valid: 43\n",
      "Total number of IDs for which there is no result for that heuristic: 16\n"
     ]
    }
   ],
   "source": [
    "present_second_score, not_present_second_score = get_eval(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5e33c84e44440780709bb81bdad23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7811), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of retreieved IDs present in original: 96\n",
      "Total number of retreieved IDs NOT present in original: 7647\n",
      "Total number of IDs for which CrossRef request is not valid: 43\n",
      "Total number of IDs for which there is no result for that heuristic: 25\n"
     ]
    }
   ],
   "source": [
    "present_third_score, not_present_third_score = get_eval(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 2nd threshold any better: False\n",
      "Is 3rd threshold any better: False\n"
     ]
    }
   ],
   "source": [
    "print('Is 2nd threshold any better: {}'.format(\n",
    "    any([True if i in not_present_first_score else False for i in present_second_score])))\n",
    "print('Is 3rd threshold any better: {}'.format(\n",
    "    any([True if i in not_present_first_score else False for i in present_third_score])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the part above, we see that the best heuristic is given by the item which has the highest score or the one which is first in the list by index. Now, we check it on the testing set..\n",
    "\n",
    "### Testing part just check the best threshold gained in the first part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total points in the testing set: 1953\n"
     ]
    }
   ],
   "source": [
    "print('Total points in the testing set: {}'.format(len(testing_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a82683d046474abdd949bb2c1ec00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of retreieved IDs present in original: 1331\n",
      "Total number of retreieved IDs NOT present in original: 617\n",
      "Total number of IDs for which CrossRef request is not valid: 5\n",
      "Total number of IDs for which there is no result for that heuristic: 0\n"
     ]
    }
   ],
   "source": [
    "## Passing 0 as the parameter as we know the first is the best heuristic\n",
    "presenting_testing_score, not_present_testing_score = get_eval(0, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
