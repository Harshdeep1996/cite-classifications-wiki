{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import glob\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from itertools import chain\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import FastText\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initializing tqdm for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'tensorflow'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print([x.name for x in local_device_protos if x.device_type == 'GPU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"wiki qss\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get auxiliary features and divide them into labels\n",
    "\n",
    "1. `ref_index`\n",
    "2. `total_words`\n",
    "3. `tags`\n",
    "4. `type_of_citation`\n",
    "\n",
    "#### can include `section` of the page in which the citation belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_journal_features = pd.read_parquet('/dlabdata1/harshdee/book_journal_features.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700000/1700000 [00:09<00:00, 177310.70it/s]\n",
      "100%|██████████| 1700000/1700000 [00:08<00:00, 203001.12it/s]\n",
      "100%|██████████| 1700000/1700000 [00:06<00:00, 281456.58it/s]\n",
      "100%|██████████| 1700000/1700000 [00:06<00:00, 246838.58it/s]\n",
      "100%|██████████| 1700000/1700000 [00:07<00:00, 214028.83it/s]\n",
      "100%|██████████| 1700000/1700000 [00:05<00:00, 298426.77it/s]\n",
      "100%|██████████| 1700000/1700000 [00:06<00:00, 278950.14it/s]\n",
      "100%|██████████| 1700000/1700000 [00:05<00:00, 284484.88it/s]\n"
     ]
    }
   ],
   "source": [
    "book_journal_features['citations'] = book_journal_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('doi\\s{0,10}=\\s{0,10}([^|]+)', 'doi = ', x))\n",
    "book_journal_features['citations'] = book_journal_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('isbn\\s{0,10}=\\s{0,10}([^|]+)', 'isbn = ', x))\n",
    "book_journal_features['citations'] = book_journal_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('pmc\\s{0,10}=\\s{0,10}([^|]+)', 'pmc = ', x))\n",
    "book_journal_features['citations'] = book_journal_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('pmid\\s{0,10}=\\s{0,10}([^|]+)', 'pmid = ', x))\n",
    "book_journal_features['citations'] = book_journal_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('url\\s{0,10}=\\s{0,10}([^|]+)', 'url = ', x))\n",
    "book_journal_features['citations'] = book_journal_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('work\\s{0,10}=\\s{0,10}([^|]+)', 'work = ', x))\n",
    "book_journal_features['citations'] = book_journal_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('newspaper\\s{0,10}=\\s{0,10}([^|]+)', 'newspaper = ', x))\n",
    "book_journal_features['citations'] = book_journal_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('website\\s{0,10}=\\s{0,10}([^|]+)', 'website = ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book       951991\n",
       "journal    748009\n",
       "Name: actual_label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_journal_features['actual_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_features = book_journal_features[book_journal_features['actual_label'] == 'journal']\n",
    "book_features = book_journal_features[book_journal_features['actual_label'] == 'book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper_data = pd.read_parquet('/dlabdata1/harshdee/newspapers_citations_features.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of newspapers: (1945390, 34)\n"
     ]
    }
   ],
   "source": [
    "print('The total number of newspapers: {}'.format(newspaper_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_index</th>\n",
       "      <th>total_words</th>\n",
       "      <th>neighboring_words</th>\n",
       "      <th>neighboring_tags</th>\n",
       "      <th>AccessDate</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Chron</th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>...</th>\n",
       "      <th>URL</th>\n",
       "      <th>Volume</th>\n",
       "      <th>citations</th>\n",
       "      <th>id</th>\n",
       "      <th>page_title</th>\n",
       "      <th>r_id</th>\n",
       "      <th>r_parentid</th>\n",
       "      <th>sections</th>\n",
       "      <th>type_of_citation</th>\n",
       "      <th>tld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1432</td>\n",
       "      <td>2326</td>\n",
       "      <td>[99, issue, page, 463, ref, ref, name=, '', Lo...</td>\n",
       "      <td>[CD, NN, NN, CD, NN, NN, NN, '', NNP, NNP, '',...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.theguardian.com/technology/2012/de...</td>\n",
       "      <td>None</td>\n",
       "      <td>{{Citation | date = 10 December 2012 | url = h...</td>\n",
       "      <td>469553</td>\n",
       "      <td>Earl of Lovelace</td>\n",
       "      <td>938238885</td>\n",
       "      <td>936441641.0</td>\n",
       "      <td>Initial Section</td>\n",
       "      <td>citation</td>\n",
       "      <td>theguardian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3923</td>\n",
       "      <td>8571</td>\n",
       "      <td>[Keely, had, gone, ., Edey, said, he, would, s...</td>\n",
       "      <td>[RB, VBD, VBN, ., NNP, VBD, PRP, MD, VB, IN, P...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1884-09-24</td>\n",
       "      <td>...</td>\n",
       "      <td>https://timesmachine.nytimes.com/timesmachine/...</td>\n",
       "      <td>None</td>\n",
       "      <td>{{Citation | last =  | first =  | author-link ...</td>\n",
       "      <td>566081</td>\n",
       "      <td>John Ernst Worrell Keely</td>\n",
       "      <td>939390025</td>\n",
       "      <td>938972992.0</td>\n",
       "      <td>Initial Section</td>\n",
       "      <td>citation</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ref_index  total_words                                  neighboring_words  \\\n",
       "0       1432         2326  [99, issue, page, 463, ref, ref, name=, '', Lo...   \n",
       "1       3923         8571  [Keely, had, gone, ., Edey, said, he, would, s...   \n",
       "\n",
       "                                    neighboring_tags AccessDate Authors  \\\n",
       "0  [CD, NN, NN, CD, NN, NN, NN, '', NNP, NNP, '',...       None    None   \n",
       "1  [RB, VBD, VBN, ., NNP, VBD, PRP, MD, VB, IN, P...       None    None   \n",
       "\n",
       "  Chapter Chron  City        Date  ...  \\\n",
       "0    None  None  None  2012-12-10  ...   \n",
       "1    None  None  None  1884-09-24  ...   \n",
       "\n",
       "                                                 URL Volume  \\\n",
       "0  https://www.theguardian.com/technology/2012/de...   None   \n",
       "1  https://timesmachine.nytimes.com/timesmachine/...   None   \n",
       "\n",
       "                                           citations      id  \\\n",
       "0  {{Citation | date = 10 December 2012 | url = h...  469553   \n",
       "1  {{Citation | last =  | first =  | author-link ...  566081   \n",
       "\n",
       "                 page_title       r_id   r_parentid         sections  \\\n",
       "0          Earl of Lovelace  938238885  936441641.0  Initial Section   \n",
       "1  John Ernst Worrell Keely  939390025  938972992.0  Initial Section   \n",
       "\n",
       "  type_of_citation          tld  \n",
       "0         citation  theguardian  \n",
       "1         citation      nytimes  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspaper_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper_data = newspaper_data[[\n",
    "    'citations', 'ref_index', 'total_words', 'neighboring_words',\n",
    "    'neighboring_tags', 'id', 'sections', 'type_of_citation'\n",
    "]]\n",
    "newspaper_data['actual_label'] = 'web'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{{cite web |last1=Rosen |first1=Jody |title=Here Are Hundreds More Artists Whose Tapes Were Destroyed in the UMG Fire |url=https://www.nytimes.com/2019/06/25/magazine/universal-music-fire-bands-list-umg.html |website=The New York Times |accessdate=28 June 2019 |date=25 June 2019}}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspaper_data.iloc[819218]['citations'] ## Example before removing the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1945390/1945390 [00:07<00:00, 270738.64it/s]\n",
      "100%|██████████| 1945390/1945390 [00:06<00:00, 292178.38it/s]\n",
      "100%|██████████| 1945390/1945390 [00:06<00:00, 304236.05it/s]\n",
      "100%|██████████| 1945390/1945390 [00:06<00:00, 303546.06it/s]\n",
      "100%|██████████| 1945390/1945390 [00:10<00:00, 188816.65it/s]\n",
      "100%|██████████| 1945390/1945390 [00:07<00:00, 262286.86it/s]\n",
      "100%|██████████| 1945390/1945390 [00:07<00:00, 275739.52it/s]\n",
      "100%|██████████| 1945390/1945390 [00:07<00:00, 268074.45it/s]\n"
     ]
    }
   ],
   "source": [
    "newspaper_data['citations'] = newspaper_data['citations'].progress_apply(\n",
    "    lambda x: re.sub('doi\\s{0,10}=\\s{0,10}([^|]+)', 'doi = ', x))\n",
    "newspaper_data['citations'] = newspaper_data['citations'].progress_apply(\n",
    "    lambda x: re.sub('isbn\\s{0,10}=\\s{0,10}([^|]+)', 'isbn = ', x))\n",
    "newspaper_data['citations'] = newspaper_data['citations'].progress_apply(\n",
    "    lambda x: re.sub('pmc\\s{0,10}=\\s{0,10}([^|]+)', 'pmc = ', x))\n",
    "newspaper_data['citations'] = newspaper_data['citations'].progress_apply(\n",
    "    lambda x: re.sub('pmid\\s{0,10}=\\s{0,10}([^|]+)', 'pmid = ', x))\n",
    "newspaper_data['citations'] = newspaper_data['citations'].progress_apply(\n",
    "    lambda x: re.sub('url\\s{0,10}=\\s{0,10}([^|]+)', 'url = ', x))\n",
    "newspaper_data['citations'] = newspaper_data['citations'].progress_apply(\n",
    "    lambda x: re.sub('work\\s{0,10}=\\s{0,10}([^|]+)', 'work = ', x))\n",
    "newspaper_data['citations'] = newspaper_data['citations'].progress_apply(\n",
    "    lambda x: re.sub('newspaper\\s{0,10}=\\s{0,10}([^|]+)', 'newspaper = ', x))\n",
    "newspaper_data['citations'] = newspaper_data['citations'].progress_apply(\n",
    "    lambda x: re.sub('website\\s{0,10}=\\s{0,10}([^|]+)', 'website = ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{{cite web |last1=Rosen |first1=Jody |title=Here Are Hundreds More Artists Whose Tapes Were Destroyed in the UMG Fire |url = |website = |accessdate=28 June 2019 |date=25 June 2019}}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspaper_data.iloc[819218]['citations'] ## Example after removing the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "entertainment_features = pd.read_parquet(\n",
    "    '/dlabdata1/harshdee/entertainment_citations_features.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "entertainment_features = entertainment_features[[\n",
    "    'ref_index', 'total_words', 'neighboring_words', 'neighboring_tags', 'id', 'sections', 'citations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{{cite web|url=https://www.billboard.com/charts/year-end/2018/top-billboard-200-albums|title=Billboard 200 Albums \\\\u2013 Year-End 2018|work=Billboard|accessdate=December 5, 2018}}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entertainment_features.iloc[23787]['citations'] ## Example before removing the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "entertainment_features['actual_label'] = 'web'\n",
    "newspaper_data.drop('type_of_citation', axis=1, inplace=True)\n",
    "book_journal_features.drop('type_of_citation', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1463652/1463652 [00:04<00:00, 304915.31it/s]\n",
      "100%|██████████| 1463652/1463652 [00:04<00:00, 299104.44it/s]\n",
      "100%|██████████| 1463652/1463652 [00:04<00:00, 307030.15it/s]\n",
      "100%|██████████| 1463652/1463652 [00:04<00:00, 309150.31it/s]\n",
      "100%|██████████| 1463652/1463652 [00:07<00:00, 198594.02it/s]\n",
      "100%|██████████| 1463652/1463652 [00:05<00:00, 257045.71it/s]\n",
      "100%|██████████| 1463652/1463652 [00:04<00:00, 314958.81it/s]\n",
      "100%|██████████| 1463652/1463652 [00:04<00:00, 294243.45it/s]\n"
     ]
    }
   ],
   "source": [
    "entertainment_features['citations'] = entertainment_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('doi\\s{0,10}=\\s{0,10}([^|]+)', 'doi = ', x))\n",
    "entertainment_features['citations'] = entertainment_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('isbn\\s{0,10}=\\s{0,10}([^|]+)', 'isbn = ', x))\n",
    "entertainment_features['citations'] = entertainment_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('pmc\\s{0,10}=\\s{0,10}([^|]+)', 'pmc = ', x))\n",
    "entertainment_features['citations'] = entertainment_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('pmid\\s{0,10}=\\s{0,10}([^|]+)', 'pmid = ', x))\n",
    "entertainment_features['citations'] = entertainment_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('url\\s{0,10}=\\s{0,10}([^|]+)', 'url = ', x))\n",
    "entertainment_features['citations'] = entertainment_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('work\\s{0,10}=\\s{0,10}([^|]+)', 'work = ', x))\n",
    "entertainment_features['citations'] = entertainment_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('newspaper\\s{0,10}=\\s{0,10}([^|]+)', 'newspaper = ', x))\n",
    "entertainment_features['citations'] = entertainment_features['citations'].progress_apply(\n",
    "    lambda x: re.sub('website\\s{0,10}=\\s{0,10}([^|]+)', 'website = ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{{cite web|url = |title=Billboard 200 Albums \\\\u2013 Year-End 2018|work = |accessdate=December 5, 2018}}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entertainment_features.iloc[23787]['citations'] ## Example after removing the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1463652/1463652 [00:04<00:00, 330150.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cite web               1124902\n",
       "Cite web                194956\n",
       "cite news                64134\n",
       "Citation                 34857\n",
       "Cite news                21032\n",
       "cite AV media             9288\n",
       "cite journal              6328\n",
       "Cite AV media             1499\n",
       "citation                  1418\n",
       "cite episode              1120\n",
       "cite press release         826\n",
       "Cite episode               660\n",
       "cite interview             637\n",
       "cite AV media notes        480\n",
       "Cite AV media notes        407\n",
       "cite book                  401\n",
       "Cite journal               268\n",
       "cite serial                 98\n",
       "cite podcast                72\n",
       "cite speech                 58\n",
       "Cite interview              41\n",
       "cite conference             40\n",
       "Cite press release          32\n",
       "Cite book                   30\n",
       "cite DVD notes              15\n",
       "cite report                 13\n",
       "cite encyclopedia           11\n",
       "Cite podcast                 9\n",
       "Cite speech                  8\n",
       "Cite conference              7\n",
       "Cite report                  4\n",
       "Cite encyclopedia            1\n",
       "Name: citations, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entertainment_features['citations'].progress_apply(\n",
    "    lambda x: re.findall('{{\\s{0,10}([^|]+)', x)[0].strip()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper_data = newspaper_data.sample(n=550000)\n",
    "entertainment_features = entertainment_features.sample(n=550000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800000, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_features = pd.concat([journal_features, book_features, newspaper_data, entertainment_features])\n",
    "dataset_with_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(dataset_with_features['actual_label'])\n",
    "dataset_with_features['label_category'] = le.transform(dataset_with_features['actual_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>actual_prob</th>\n",
       "      <th>citations</th>\n",
       "      <th>id</th>\n",
       "      <th>neighboring_tags</th>\n",
       "      <th>neighboring_words</th>\n",
       "      <th>ref_index</th>\n",
       "      <th>sections</th>\n",
       "      <th>total_words</th>\n",
       "      <th>type_of_citation</th>\n",
       "      <th>label_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [actual_label, actual_prob, citations, id, neighboring_tags, neighboring_words, ref_index, sections, total_words, type_of_citation, label_category]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_features[dataset_with_features['actual_label'] == 'entertainment'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>actual_prob</th>\n",
       "      <th>citations</th>\n",
       "      <th>id</th>\n",
       "      <th>neighboring_tags</th>\n",
       "      <th>neighboring_words</th>\n",
       "      <th>ref_index</th>\n",
       "      <th>sections</th>\n",
       "      <th>total_words</th>\n",
       "      <th>type_of_citation</th>\n",
       "      <th>label_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401438</th>\n",
       "      <td>web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{{cite news|url = |title=Honeybee mobs overpow...</td>\n",
       "      <td>1002559</td>\n",
       "      <td>[NN, NNP, VBZ, NNP, NN, NNP, NN, NNP, CD, NN, ...</td>\n",
       "      <td>[first1, Michio, last2, Sakamoto, first2, Fumi...</td>\n",
       "      <td>5179</td>\n",
       "      <td>Predation</td>\n",
       "      <td>6474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual_label  actual_prob  \\\n",
       "401438          web          NaN   \n",
       "\n",
       "                                                citations       id  \\\n",
       "401438  {{cite news|url = |title=Honeybee mobs overpow...  1002559   \n",
       "\n",
       "                                         neighboring_tags  \\\n",
       "401438  [NN, NNP, VBZ, NNP, NN, NNP, NN, NNP, CD, NN, ...   \n",
       "\n",
       "                                        neighboring_words  ref_index  \\\n",
       "401438  [first1, Michio, last2, Sakamoto, first2, Fumi...       5179   \n",
       "\n",
       "         sections  total_words type_of_citation  label_category  \n",
       "401438  Predation         6474              NaN               2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_features[dataset_with_features['actual_label'] == 'web'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>actual_prob</th>\n",
       "      <th>citations</th>\n",
       "      <th>id</th>\n",
       "      <th>neighboring_tags</th>\n",
       "      <th>neighboring_words</th>\n",
       "      <th>ref_index</th>\n",
       "      <th>sections</th>\n",
       "      <th>total_words</th>\n",
       "      <th>type_of_citation</th>\n",
       "      <th>label_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450150</th>\n",
       "      <td>book</td>\n",
       "      <td>0.45</td>\n",
       "      <td>{{cite book |title=Barris TV and Movie Cars |p...</td>\n",
       "      <td>68485</td>\n",
       "      <td>[NNP, CD, CD, NN, DT, NNPS, VBD, VBN, IN, NNP,...</td>\n",
       "      <td>[February, 18, 2016, ref, The, Explorers, were...</td>\n",
       "      <td>5580</td>\n",
       "      <td>Initial Section</td>\n",
       "      <td>20807</td>\n",
       "      <td>cite book</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual_label  actual_prob  \\\n",
       "450150         book         0.45   \n",
       "\n",
       "                                                citations     id  \\\n",
       "450150  {{cite book |title=Barris TV and Movie Cars |p...  68485   \n",
       "\n",
       "                                         neighboring_tags  \\\n",
       "450150  [NNP, CD, CD, NN, DT, NNPS, VBD, VBN, IN, NNP,...   \n",
       "\n",
       "                                        neighboring_words  ref_index  \\\n",
       "450150  [February, 18, 2016, ref, The, Explorers, were...       5580   \n",
       "\n",
       "               sections  total_words type_of_citation  label_category  \n",
       "450150  Initial Section        20807        cite book               0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_features[dataset_with_features['actual_label'] == 'book'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>actual_prob</th>\n",
       "      <th>citations</th>\n",
       "      <th>id</th>\n",
       "      <th>neighboring_tags</th>\n",
       "      <th>neighboring_words</th>\n",
       "      <th>ref_index</th>\n",
       "      <th>sections</th>\n",
       "      <th>total_words</th>\n",
       "      <th>type_of_citation</th>\n",
       "      <th>label_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1847498</th>\n",
       "      <td>journal</td>\n",
       "      <td>0.55</td>\n",
       "      <td>{{Cite journal|last=Tauzin|first=Tibor|last2=G...</td>\n",
       "      <td>488083</td>\n",
       "      <td>[CC, IN, PRP, MD, VB, JJ, NNS, VBG, IN, DT, JJ...</td>\n",
       "      <td>[and, therefore, it, can, have, different, mea...</td>\n",
       "      <td>3860</td>\n",
       "      <td>Initial Section</td>\n",
       "      <td>18454</td>\n",
       "      <td>cite journal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual_label  actual_prob  \\\n",
       "1847498      journal         0.55   \n",
       "\n",
       "                                                 citations      id  \\\n",
       "1847498  {{Cite journal|last=Tauzin|first=Tibor|last2=G...  488083   \n",
       "\n",
       "                                          neighboring_tags  \\\n",
       "1847498  [CC, IN, PRP, MD, VB, JJ, NNS, VBG, IN, DT, JJ...   \n",
       "\n",
       "                                         neighboring_words  ref_index  \\\n",
       "1847498  [and, therefore, it, can, have, different, mea...       3860   \n",
       "\n",
       "                sections  total_words type_of_citation  label_category  \n",
       "1847498  Initial Section        18454     cite journal               1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_features[dataset_with_features['actual_label'] == 'journal'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [00:07<00:00, 394320.76it/s]\n"
     ]
    }
   ],
   "source": [
    "## Convert citations' text to UTF-8\n",
    "dataset_with_features['citations'] = dataset_with_features['citations'].progress_apply(lambda x: x.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "web        1100000\n",
       "book        951991\n",
       "journal     748009\n",
       "Name: actual_label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_features['actual_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## clearing up memory\n",
    "del book_journal_features\n",
    "del newspaper_data\n",
    "del entertainment_features\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove rows which have duplicate ID and citations since they are just the same examples\n",
    "# dataset_with_features = dataset_with_features.drop_duplicates(subset=['id', 'citations']) ## keeps first row\n",
    "# dataset_with_features = dataset_with_features.reset_index(drop=True)\n",
    "# dataset_with_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please save this file and use it - as an intermediate file if you want to use it somewhere else\n",
    "## dataset_with_features.to_csv('dataset_with_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the unique `sections` and one hot encoding it to get a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only processing auxiliary features which are going to be used in the neural network\n",
    "auxiliary_features = dataset_with_features[\n",
    "    ['sections', 'citations', 'id', 'ref_index',\n",
    "     'total_words', 'neighboring_tags', 'label_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_features['sections'] = auxiliary_features['sections'].apply(\n",
    "    lambda x: x.encode('utf-8') if isinstance(x, unicode) else str(x))\n",
    "auxiliary_features['sections'] = auxiliary_features['sections'].astype(str)\n",
    "auxiliary_features['sections'] = auxiliary_features['sections'].apply(lambda x: x.split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_counts = pd.Series(Counter(chain.from_iterable(x for x in auxiliary_features.sections)))\n",
    "largest_sections = section_counts.nlargest(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# largest_sections.to_csv('/dlabdata1/harshdee/largest_sections.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [00:11<00:00, 251219.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Change section to `OTHERS` if occurence of the section is not in the 150 largest sections\n",
    "auxiliary_features['sections'] = auxiliary_features['sections'].progress_apply(\n",
    "    lambda x: list(set(['Others' if i not in largest_sections else i for i in x]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sections</th>\n",
       "      <th>citations</th>\n",
       "      <th>id</th>\n",
       "      <th>ref_index</th>\n",
       "      <th>total_words</th>\n",
       "      <th>neighboring_tags</th>\n",
       "      <th>label_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1847498</th>\n",
       "      <td>[Initial Section]</td>\n",
       "      <td>{{Cite journal|last=Tauzin|first=Tibor|last2=G...</td>\n",
       "      <td>488083</td>\n",
       "      <td>3860</td>\n",
       "      <td>18454</td>\n",
       "      <td>[CC, IN, PRP, MD, VB, JJ, NNS, VBG, IN, DT, JJ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219190</th>\n",
       "      <td>[Initial Section]</td>\n",
       "      <td>{{cite journal |vauthors=Byerley JS, Gable K |...</td>\n",
       "      <td>46431158</td>\n",
       "      <td>911</td>\n",
       "      <td>2000</td>\n",
       "      <td>[NN, '', JJ, NN, NNP, NNP, NNP, NNP, NNS, JJ, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180322</th>\n",
       "      <td>[Initial Section]</td>\n",
       "      <td>{{cite journal |last1=Almaslamani |first1=Muna...</td>\n",
       "      <td>41089873</td>\n",
       "      <td>1952</td>\n",
       "      <td>2628</td>\n",
       "      <td>[NNP, NNP, NNP, VBG, NN, IN, JJ, NN, VBN, IN, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119748</th>\n",
       "      <td>[Function]</td>\n",
       "      <td>{{cite journal | vauthors = Rash BG, Lim HD, B...</td>\n",
       "      <td>5662589</td>\n",
       "      <td>1860</td>\n",
       "      <td>3336</td>\n",
       "      <td>[VB, DT, NN, IN, JJ, NN, CC, DT, NN, IN, NN, W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921257</th>\n",
       "      <td>[Initial Section]</td>\n",
       "      <td>{{cite journal|last=Clark|first=Herbert H.|aut...</td>\n",
       "      <td>6470064</td>\n",
       "      <td>2011</td>\n",
       "      <td>4751</td>\n",
       "      <td>[NNS, IN, NN, NN, TO, VB, DT, JJ, NN, VBN, IN,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sections                                          citations  \\\n",
       "1847498  [Initial Section]  {{Cite journal|last=Tauzin|first=Tibor|last2=G...   \n",
       "3219190  [Initial Section]  {{cite journal |vauthors=Byerley JS, Gable K |...   \n",
       "2180322  [Initial Section]  {{cite journal |last1=Almaslamani |first1=Muna...   \n",
       "2119748         [Function]  {{cite journal | vauthors = Rash BG, Lim HD, B...   \n",
       "921257   [Initial Section]  {{cite journal|last=Clark|first=Herbert H.|aut...   \n",
       "\n",
       "               id  ref_index  total_words  \\\n",
       "1847498    488083       3860        18454   \n",
       "3219190  46431158        911         2000   \n",
       "2180322  41089873       1952         2628   \n",
       "2119748   5662589       1860         3336   \n",
       "921257    6470064       2011         4751   \n",
       "\n",
       "                                          neighboring_tags  label_category  \n",
       "1847498  [CC, IN, PRP, MD, VB, JJ, NNS, VBG, IN, DT, JJ...               1  \n",
       "3219190  [NN, '', JJ, NN, NNP, NNP, NNP, NNP, NNS, JJ, ...               1  \n",
       "2180322  [NNP, NNP, NNP, VBG, NN, IN, JJ, NN, VBN, IN, ...               1  \n",
       "2119748  [VB, DT, NN, IN, JJ, NN, CC, DT, NN, IN, NN, W...               1  \n",
       "921257   [NNS, IN, NN, NN, TO, VB, DT, JJ, NN, VBN, IN,...               1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auxiliary_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_dummies = pd.get_dummies(auxiliary_features.sections.apply(pd.Series).stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_features = auxiliary_features.join(section_dummies.sum(level=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations</th>\n",
       "      <th>id</th>\n",
       "      <th>ref_index</th>\n",
       "      <th>total_words</th>\n",
       "      <th>neighboring_tags</th>\n",
       "      <th>label_category</th>\n",
       "      <th>20th century</th>\n",
       "      <th>Accolades</th>\n",
       "      <th>Adverse effects</th>\n",
       "      <th>Aftermath</th>\n",
       "      <th>...</th>\n",
       "      <th>Taxonomy</th>\n",
       "      <th>Terminology</th>\n",
       "      <th>Timeline</th>\n",
       "      <th>Track listing</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Types</th>\n",
       "      <th>Usage in media</th>\n",
       "      <th>Uses</th>\n",
       "      <th>Work</th>\n",
       "      <th>Works</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{{Citation | date = 10 December 2012 | url = |...</td>\n",
       "      <td>469553</td>\n",
       "      <td>1432</td>\n",
       "      <td>2326</td>\n",
       "      <td>[CD, NN, NN, CD, NN, NN, NN, '', NNP, NNP, '',...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{{Citation | url = | title=Donny Osmond, Moon ...</td>\n",
       "      <td>17321557</td>\n",
       "      <td>1624</td>\n",
       "      <td>2013</td>\n",
       "      <td>[:,JJ,NN,:,NN,WRB,NN,VB,JJ,JJ,NN,:,NN,:,JJ,NN,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{{cite journal|last=Stadler |first=L. J. |auth...</td>\n",
       "      <td>627</td>\n",
       "      <td>15433</td>\n",
       "      <td>26710</td>\n",
       "      <td>[JJ, NN, NNS, CC, NN, IN, NNP, NNP, ., JJ, NN,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{{Citation | last = ''[[The New York Times]]''...</td>\n",
       "      <td>28571997</td>\n",
       "      <td>546</td>\n",
       "      <td>1518</td>\n",
       "      <td>['', DT, NNP, NNP, NNP, '', NNP, RB, VBP, JJ, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{{cite book|author1=Steven L. Small|author2=Ga...</td>\n",
       "      <td>677</td>\n",
       "      <td>605</td>\n",
       "      <td>5244</td>\n",
       "      <td>[DT, NN, VBZ, ., VB, JJ, '', NNP, '', NN, RB, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           citations        id  ref_index  \\\n",
       "0  {{Citation | date = 10 December 2012 | url = |...    469553       1432   \n",
       "1  {{Citation | url = | title=Donny Osmond, Moon ...  17321557       1624   \n",
       "2  {{cite journal|last=Stadler |first=L. J. |auth...       627      15433   \n",
       "2  {{Citation | last = ''[[The New York Times]]''...  28571997        546   \n",
       "3  {{cite book|author1=Steven L. Small|author2=Ga...       677        605   \n",
       "\n",
       "   total_words                                   neighboring_tags  \\\n",
       "0         2326  [CD, NN, NN, CD, NN, NN, NN, '', NNP, NNP, '',...   \n",
       "1         2013  [:,JJ,NN,:,NN,WRB,NN,VB,JJ,JJ,NN,:,NN,:,JJ,NN,...   \n",
       "2        26710  [JJ, NN, NNS, CC, NN, IN, NNP, NNP, ., JJ, NN,...   \n",
       "2         1518  ['', DT, NNP, NNP, NNP, '', NNP, RB, VBP, JJ, ...   \n",
       "3         5244  [DT, NN, VBZ, ., VB, JJ, '', NNP, '', NN, RB, ...   \n",
       "\n",
       "   label_category  20th century  Accolades  Adverse effects  Aftermath  ...  \\\n",
       "0               2             0          0                0          0  ...   \n",
       "1               2             0          0                0          0  ...   \n",
       "2               1             0          0                0          0  ...   \n",
       "2               2             0          0                0          0  ...   \n",
       "3               0             0          0                0          0  ...   \n",
       "\n",
       "   Taxonomy  Terminology  Timeline  Track listing  Treatment  Types  \\\n",
       "0         0            0         0              0          0      0   \n",
       "1         0            0         0              0          0      0   \n",
       "2         0            0         0              0          0      0   \n",
       "2         0            0         0              0          0      0   \n",
       "3         0            0         0              0          0      0   \n",
       "\n",
       "   Usage in media  Uses  Work  Works  \n",
       "0               0     0     0      0  \n",
       "1               0     0     0      0  \n",
       "2               0     0     0      0  \n",
       "2               0     0     0      0  \n",
       "3               0     0     0      0  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auxiliary_features.drop('sections', axis=1, inplace=True)\n",
    "auxiliary_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the `type of citations` and one hot encoding it to get a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get one hot encoding of citation_type column\n",
    "# citation_type_encoding = pd.get_dummies(auxiliary_features['citation_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop column citation_type as it is now encoded and join it\n",
    "# auxiliary_features = auxiliary_features.drop('citation_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concat columns of the dummies along the axis with the matching index\n",
    "# auxiliary_features = pd.concat([auxiliary_features, citation_type_encoding], axis=1)\n",
    "# auxiliary_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see for the feature `total_number_of_words`, the mean and median **(since it is more robust in nature!)** are pretty high for articles which are `not` journal or books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mean length of entertainment articles: 7388.19177443\n",
      "Total median length of entertainment articles: 3215.0\n"
     ]
    }
   ],
   "source": [
    "print('Total mean length of entertainment articles: {}'.format( ## Journal - length is less\n",
    "    auxiliary_features[auxiliary_features['label_category'] == 1]['total_words'].mean()))\n",
    "print('Total median length of entertainment articles: {}'.format(\n",
    "    auxiliary_features[auxiliary_features['label_category'] == 1]['total_words'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mean length of journal articles: 10300.7014891\n",
      "Total median length of journal articles: 4819.0\n"
     ]
    }
   ],
   "source": [
    "print('Total mean length of journal articles: {}'.format( ## Rest of the article have larger length\n",
    "    auxiliary_features[auxiliary_features['label_category'] == 2]['total_words'].mean()))\n",
    "print('Total median length of journal articles: {}'.format(\n",
    "    auxiliary_features[auxiliary_features['label_category'] == 2]['total_words'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mean length of book articles: 7080.08309953\n",
      "Total median length of book articles: 2893.0\n"
     ]
    }
   ],
   "source": [
    "print('Total mean length of book articles: {}'.format( ## Books - length is less\n",
    "    auxiliary_features[auxiliary_features['label_category'] == 0]['total_words'].mean()))\n",
    "print('Total median length of book articles: {}'.format(\n",
    "    auxiliary_features[auxiliary_features['label_category'] == 0]['total_words'].median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the `neighboring_tags` and making an encoder dictionary for it\n",
    "\n",
    "To have more info about how what tag mean what: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_tag_features = dataset_with_features[['id', 'citations', 'neighboring_tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation_tag_features['neighboring_tags'] = citation_tag_features['neighboring_tags'].progress_apply(\n",
    "#     lambda x: x.replace(\"'\", \"\").replace('[', '').replace(']', '').replace('\\n', '').split(' ')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'NN', u\"''\", u'JJ', u'NN', u'NNP', u'NNP', u'NNP', u'NNP', u'NNS',\n",
       "       u'JJ'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_tag_features.iloc[1]['neighboring_tags'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count for each POS tag so that we have an estimation as to how many are there\n",
    "tag_counts = pd.Series(Counter(chain.from_iterable(x for x in citation_tag_features.neighboring_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LS        3\n",
       "`       278\n",
       "``      433\n",
       "H       603\n",
       "U       603\n",
       "UH     1427\n",
       "Y      1618\n",
       "SYM    1956\n",
       "X      2258\n",
       "WP$    3590\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considering the 10 smallest tags and checking which one does not have resemblance\n",
    "tag_counts.nsmallest(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_counts.to_csv('/dlabdata1/harshdee/tag_counts.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to replace `LS`, `the 2 backquotes` and the `the dollar symbol` since they do not have too much use case and do not give too much information about the context of the neighboring citation text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [01:26<00:00, 32348.72it/s]\n"
     ]
    }
   ],
   "source": [
    "OTHER_TAGS = ['LS', '``', '$']\n",
    "citation_tag_features['neighboring_tags'] = citation_tag_features['neighboring_tags'].progress_apply(\n",
    "    lambda x: [i if i not in OTHER_TAGS else 'Others' for i in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `count vectorizer` to represent the `POS tags` as a vector where each element of the vector represents the count of that tag in that particular citation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() # Instantiate the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [00:09<00:00, 300476.03it/s]\n"
     ]
    }
   ],
   "source": [
    "citation_tag_features['neighboring_tags'] = citation_tag_features['neighboring_tags'].progress_apply(\n",
    "    lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_neighboring_tags = cv.fit_transform(citation_tag_features['neighboring_tags'])\n",
    "transformed_neighboring_tags = pd.DataFrame(transformed_neighboring_tags.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>citations</th>\n",
       "      <th>neighboring_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1847498</th>\n",
       "      <td>488083</td>\n",
       "      <td>{{Cite journal|last=Tauzin|first=Tibor|last2=G...</td>\n",
       "      <td>CC IN PRP MD VB JJ NNS VBG IN DT JJ NN NN IN N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219190</th>\n",
       "      <td>46431158</td>\n",
       "      <td>{{cite journal |vauthors=Byerley JS, Gable K |...</td>\n",
       "      <td>NN '' JJ NN NNP NNP NNP NNP NNS JJ NN NN NN IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180322</th>\n",
       "      <td>41089873</td>\n",
       "      <td>{{cite journal |last1=Almaslamani |first1=Muna...</td>\n",
       "      <td>NNP NNP NNP VBG NN IN JJ NN VBN IN NNP VBP RB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119748</th>\n",
       "      <td>5662589</td>\n",
       "      <td>{{cite journal | vauthors = Rash BG, Lim HD, B...</td>\n",
       "      <td>VB DT NN IN JJ NN CC DT NN IN NN WDT VBZ DT NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921257</th>\n",
       "      <td>6470064</td>\n",
       "      <td>{{cite journal|last=Clark|first=Herbert H.|aut...</td>\n",
       "      <td>NNS IN NN NN TO VB DT JJ NN VBN IN DT NN DT IN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                          citations  \\\n",
       "1847498    488083  {{Cite journal|last=Tauzin|first=Tibor|last2=G...   \n",
       "3219190  46431158  {{cite journal |vauthors=Byerley JS, Gable K |...   \n",
       "2180322  41089873  {{cite journal |last1=Almaslamani |first1=Muna...   \n",
       "2119748   5662589  {{cite journal | vauthors = Rash BG, Lim HD, B...   \n",
       "921257    6470064  {{cite journal|last=Clark|first=Herbert H.|aut...   \n",
       "\n",
       "                                          neighboring_tags  \n",
       "1847498  CC IN PRP MD VB JJ NNS VBG IN DT JJ NN NN IN N...  \n",
       "3219190  NN '' JJ NN NNP NNP NNP NNP NNS JJ NN NN NN IN...  \n",
       "2180322  NNP NNP NNP VBG NN IN JJ NN VBN IN NNP VBP RB ...  \n",
       "2119748  VB DT NN IN JJ NN CC DT NN IN NN WDT VBZ DT NN...  \n",
       "921257   NNS IN NN NN TO VB DT JJ NN VBN IN DT NN DT IN...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_tag_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2800000, 35), (2800000, 3))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_neighboring_tags.shape, citation_tag_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_tag_features = citation_tag_features.reset_index(drop=True)\n",
    "citation_tag_features = pd.concat([citation_tag_features, transformed_neighboring_tags], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>citations</th>\n",
       "      <th>cc</th>\n",
       "      <th>cd</th>\n",
       "      <th>dt</th>\n",
       "      <th>ex</th>\n",
       "      <th>fw</th>\n",
       "      <th>in</th>\n",
       "      <th>jj</th>\n",
       "      <th>jjr</th>\n",
       "      <th>...</th>\n",
       "      <th>vb</th>\n",
       "      <th>vbd</th>\n",
       "      <th>vbg</th>\n",
       "      <th>vbn</th>\n",
       "      <th>vbp</th>\n",
       "      <th>vbz</th>\n",
       "      <th>wdt</th>\n",
       "      <th>wikicode</th>\n",
       "      <th>wp</th>\n",
       "      <th>wrb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>488083</td>\n",
       "      <td>{{Cite journal|last=Tauzin|first=Tibor|last2=G...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46431158</td>\n",
       "      <td>{{cite journal |vauthors=Byerley JS, Gable K |...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41089873</td>\n",
       "      <td>{{cite journal |last1=Almaslamani |first1=Muna...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5662589</td>\n",
       "      <td>{{cite journal | vauthors = Rash BG, Lim HD, B...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6470064</td>\n",
       "      <td>{{cite journal|last=Clark|first=Herbert H.|aut...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                          citations  cc  cd  dt  \\\n",
       "0    488083  {{Cite journal|last=Tauzin|first=Tibor|last2=G...   3   0   4   \n",
       "1  46431158  {{cite journal |vauthors=Byerley JS, Gable K |...   0   1   1   \n",
       "2  41089873  {{cite journal |last1=Almaslamani |first1=Muna...   1   1   0   \n",
       "3   5662589  {{cite journal | vauthors = Rash BG, Lim HD, B...   2   0   4   \n",
       "4   6470064  {{cite journal|last=Clark|first=Herbert H.|aut...   2   0   7   \n",
       "\n",
       "   ex  fw  in  jj  jjr  ...  vb  vbd  vbg  vbn  vbp  vbz  wdt  wikicode  wp  \\\n",
       "0   0   0   6   6    0  ...   2    1    3    0    0    0    0         0   0   \n",
       "1   0   0   2   7    0  ...   0    0    0    0    0    0    0         0   0   \n",
       "2   0   0   4   6    0  ...   0    0    1    1    1    0    0         0   0   \n",
       "3   0   0   4   3    0  ...   3    0    0    1    1    2    1         0   0   \n",
       "4   0   0   4   2    1  ...   3    0    1    2    0    1    0         0   0   \n",
       "\n",
       "   wrb  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_tag_features.drop('neighboring_tags', axis=1, inplace=True)\n",
    "citation_tag_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for the LSTM - more time sequence related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation's original text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate dataframe for preprocessing citation text\n",
    "citation_text_features = dataset_with_features[['id', 'citations', 'label_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [00:28<00:00, 99473.56it/s] \n"
     ]
    }
   ],
   "source": [
    "# Convert the citation into a list by breaking it down into characters\n",
    "citation_text_features['characters'] = citation_text_features['citations'].progress_apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u' ', u'!', u'\"', u'#', u'$', u'%', u'&', u''', u'(', u')', u'*', u'+',\n",
       "       u',', u'-', u'.', u'/', u'0', u'1', u'2', u'3', u'4', u'5', u'6', u'7',\n",
       "       u'8', u'9', u':', u';', u'<', u'=', u'>', u'?', u'@', u'A', u'B', u'C',\n",
       "       u'D', u'E', u'F', u'G', u'H', u'I', u'J', u'K', u'L', u'M', u'N', u'O',\n",
       "       u'P', u'Q', u'R', u'S', u'T', u'U', u'V', u'W', u'X', u'Y', u'Z', u'[',\n",
       "       u'\\', u']', u'^', u'_', u'`', u'a', u'b', u'c', u'd', u'e', u'f', u'g',\n",
       "       u'h', u'i', u'j', u'k', u'l', u'm', u'n', u'o', u'p', u'q', u'r', u's',\n",
       "       u't', u'u', u'v', u'w', u'x', u'y', u'z', u'{', u'|', u'}', u'~'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the character counts for each unique character\n",
    "char_counts = pd.Series(Counter(chain.from_iterable(x for x in citation_text_features.characters)))\n",
    "char_counts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of the longest citation in terms of characters is: 146206\n",
      "The mean length of the longest citation in terms of characters is: 216.880559286\n",
      "The median length of the longest citation in terms of characters is: 191.0\n"
     ]
    }
   ],
   "source": [
    "print('The max length of the longest citation in terms of characters is: {}'.format(\n",
    "    max(citation_text_features.characters.apply(lambda x: len(x)))))\n",
    "\n",
    "print('The mean length of the longest citation in terms of characters is: {}'.format(\n",
    "    citation_text_features.characters.apply(lambda x: len(x)).mean()))\n",
    "\n",
    "print('The median length of the longest citation in terms of characters is: {}'.format(\n",
    "    citation_text_features.characters.apply(lambda x: len(x)).median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary for creating a mapping between the char and the corresponding index\n",
    "char2ind = {char: i for i, char in enumerate(char_counts.index)}\n",
    "ind2char = {i: char for i, char in enumerate(char_counts.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each character into the citation to its corresponding index and store it in a list\n",
    "X_char = []\n",
    "for citation in citation_text_features.citations:\n",
    "    citation_chars = []\n",
    "    for character in citation:\n",
    "        citation_chars.append(char2ind[character])\n",
    "        \n",
    "    X_char.append(citation_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the median length of the citation is 282, we have padded the input till 400 to get extra information which would be fed into the character embedding neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_char = pad_sequences(X_char, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Append the citation character list with their corresponding lists for making a dataset\n",
    "# # for getting the character embeddings\n",
    "# data = []\n",
    "# for i in tqdm(range(len(X_char))):\n",
    "#     data.append((X_char[i], int(citation_text_features.iloc[i]['label_category'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate out the training data and labels for further verification use\n",
    "# features = [i[0] for i in data]\n",
    "# labels = [i[1] for i in data]\n",
    "# ## Changing it to dummy labels - identifier vs non identifier\n",
    "# labels = [i for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter(labels) ## 1401521, 1651833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Splitting the data into training and testing\n",
    "# training_data, testing_data, training_labels, testing_labels = train_test_split(\n",
    "#     features, labels, train_size=0.9, shuffle=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to feed in the 400 character input since our median length comes out to be approximately 282 and train it on a dummy task - if the citation is scientific or not and get the embedding layer which would contain the representation for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "\n",
    "# categorical_labels = to_categorical(training_labels, num_classes=3)\n",
    "# categorical_test_labels = to_categorical(testing_labels, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def citation_embedding_model():\n",
    "    \"\"\"\n",
    "    Citation embedding generator model where the dimension of the embedding is 50.\n",
    "    \"\"\"\n",
    "    main_input = Input(shape=(400, ), name='characters')\n",
    "    # input dim is basically the vocab size\n",
    "    emb = Embedding(input_dim=95, output_dim = 300, name='citation_embedding')(main_input)\n",
    "    rnn = Bidirectional(LSTM(20))\n",
    "    x = rnn(emb)\n",
    "    de = Dense(3, activation='softmax')(x)\n",
    "    model = Model(inputs = main_input, outputs = de)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model and generate the summary\n",
    "model = citation_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "characters (InputLayer)      (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "citation_embedding (Embeddin (None, 400, 300)          28500     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40)                51360     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 123       \n",
      "=================================================================\n",
      "Total params: 79,983\n",
      "Trainable params: 79,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Generator to create batches of data so that processing is easy.\n",
    "    \n",
    "    :param: features: the features of the model.\n",
    "    :param: labels: the labels of the model.\n",
    "    :param: batch_size: the size of the batch\n",
    "    \"\"\"\n",
    "    # Create empty arrays to contain batch of features and labels\n",
    "    batch_features = np.zeros((batch_size, 400))\n",
    "    batch_labels = np.zeros((batch_size, 3))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index = np.random.choice(len(features), 1)[0]\n",
    "            batch_features[i] = features[index]\n",
    "            batch_labels[i] = categorical_labels[index]\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with the data being generated by the generator with a batch size of 64\n",
    "# and number of epochs to be set to 15\n",
    "# hist = model.fit_generator(\n",
    "#     generator(training_data, categorical_labels, 512), steps_per_epoch=4000, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation of embedding model\n",
    "# y_predicted_proba = model.predict(np.array(testing_data))\n",
    "# predicted_class = np.argmax(y_predicted_proba, axis=1)\n",
    "# accuracy_score(testing_labels, predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch/harshdee/tensorflow_cpu/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the model so that we can retrieve it later\n",
    "# model.save('/dlabdata1/harshdee/embedding_model.h5')\n",
    "from keras.models import load_model\n",
    "model = load_model('/dlabdata1/harshdee/embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 300)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the `citation_embedding` layer and get the weights for each character\n",
    "citation_layer = model.get_layer('citation_embedding')\n",
    "citation_weights = citation_layer.get_weights()[0]\n",
    "citation_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03709625,  0.04958485,  0.01190331, -0.01536058, -0.02582742,\n",
       "       -0.00217483,  0.08311249,  0.06200508, -0.08459523, -0.04255919,\n",
       "        0.0143231 , -0.01487149, -0.03491046, -0.04084954,  0.00435642,\n",
       "       -0.03313474, -0.01999018, -0.05731481, -0.01956906,  0.0226227 ,\n",
       "       -0.03271348,  0.00799032,  0.0249096 , -0.00482269, -0.03595483,\n",
       "        0.09026573, -0.02702151,  0.0100947 , -0.05867961,  0.05779125,\n",
       "        0.05369785,  0.10009865,  0.06406695,  0.02678208, -0.00046256,\n",
       "        0.00182868, -0.06260174,  0.09839807, -0.03899828,  0.0603345 ,\n",
       "        0.05612418,  0.14331605, -0.05818555,  0.09527376, -0.03321271,\n",
       "       -0.00525861,  0.06318327, -0.01527527,  0.03295157, -0.01681761,\n",
       "        0.08902843,  0.13985208,  0.035852  ,  0.0349258 , -0.03233176,\n",
       "        0.00341616,  0.00032616,  0.09980483,  0.02019689, -0.02741743,\n",
       "        0.01315569,  0.08160345,  0.05272087,  0.04602867,  0.04264879,\n",
       "        0.03988118, -0.01963122, -0.02536223, -0.01573488, -0.05283005,\n",
       "        0.03838497,  0.07740206,  0.06695451,  0.00710508, -0.0429761 ,\n",
       "       -0.00630073, -0.07619786,  0.03504869,  0.09039176,  0.01558858,\n",
       "        0.04265645,  0.03345951, -0.01479871,  0.01506421,  0.05093784,\n",
       "        0.07321022, -0.05130187, -0.03472692, -0.04310887,  0.02629239,\n",
       "       -0.02758791, -0.04002747,  0.02566252,  0.07947636, -0.04788662,\n",
       "        0.02495757,  0.06822391, -0.03960632,  0.07702351,  0.0442193 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of the first element of an embedding\n",
    "citation_weights[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [13:26<00:00, 3469.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Map the embedding of each character to the character in each corresponding citation and aggregate (sum)\n",
    "citation_text_features['embedding'] = citation_text_features['characters'].progress_apply(\n",
    "    lambda x: sum([citation_weights[char2ind[c]] for c in x])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [00:48<00:00, 58094.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the citation embeddings so that we can check for their similarity later\n",
    "citation_text_features['embedding'] = citation_text_features['embedding'].progress_apply(\n",
    "    lambda x: x/ np.linalg.norm(x, axis=0).reshape((-1, 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the sum of the embedding to be summed up to 1\n",
    "np.sum(np.square(citation_text_features['embedding'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Graph for citation text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just considering 20 since otherwise it will be computationally extensive\n",
    "# citation_text_and_embeddings = citation_text_features[['citation', 'embedding']][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation_text_and_embeddings['embedding'] = citation_text_and_embeddings['embedding'].progress_apply(\n",
    "#     lambda x: x[0].tolist()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tsne_embedding_plot():\n",
    "#     labels = []\n",
    "#     tokens = []\n",
    "\n",
    "#     index = 0\n",
    "#     for row in citation_text_and_embeddings:\n",
    "#         tokens.append(row['embedding'])\n",
    "#         labels.append(str(index))\n",
    "#         index += 1\n",
    "    \n",
    "#     # Perplexity takes into account the global and local features\n",
    "#     # We are using dimensionality reduciton for 2 features and taking 2500 iterations into account\n",
    "#     tsne_model = TSNE(perplexity=40, n_components=2, n_iter=2500, random_state=0)\n",
    "#     new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for value in new_values:\n",
    "#         x.append(value[0])\n",
    "#         y.append(value[1])\n",
    "        \n",
    "#     plt.figure(figsize=(10, 10)) \n",
    "#     for i in range(len(x)):\n",
    "#         plt.scatter(x[i],y[i])\n",
    "#         plt.annotate(labels[i], xy=(x[i], y[i]), xytext=(5, 2),\n",
    "#                      textcoords='offset points', ha='right', va='bottom')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne_embedding_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of citation embeddings which is close to each other\n",
    "# citation_text_and_embeddings[citation_text_and_embeddings.index.isin([14, 477])] # (51, 243), (0, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Similiarity of 2 citations which are very similar\n",
    "# result_similar = 1 - spatial.distance.cosine(\n",
    "#     citation_text_and_embeddings.iloc[14]['embedding'],\n",
    "#     citation_text_and_embeddings.iloc[477]['embedding']\n",
    "# )\n",
    "# result_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of citation embeddings which is NOT close to each other and are different\n",
    "# citation_text_and_embeddings[citation_text_and_embeddings.index.isin([42, 124])] # (6, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similiarity of 2 citations which are not similar\n",
    "# result_different = 1 - spatial.distance.cosine(\n",
    "#     citation_text_and_embeddings.iloc[42]['embedding'],\n",
    "#     citation_text_and_embeddings.iloc[124]['embedding']\n",
    "# )\n",
    "# result_different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText embeddings for neighboring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained embedding model on wikipedia\n",
    "model = FastText.load_fasttext_format('/dlabdata1/harshdee/wiki.en.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate dataframe for preprocessing citation words\n",
    "citation_word_features = dataset_with_features[['id', 'citations', 'neighboring_words', 'label_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [01:29<00:00, 31308.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Lowercase all the neighboring words for each of the citations\n",
    "citation_word_features['neighboring_words'] = citation_word_features['neighboring_words'].progress_apply(\n",
    "    lambda x: [i.lower() for i in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the total unique words with their respective counts in the total dataset. This is done in order to remove words which are of low frequency and will potentially act as noise to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.Series(Counter(chain.from_iterable(x for x in citation_word_features.neighboring_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 5730137\n",
      "Total number of words whose occurence is less than 4: 5287233\n",
      "Difference: 442904\n"
     ]
    }
   ],
   "source": [
    "threshold = 4\n",
    "\n",
    "x = len(word_counts)\n",
    "y = len(word_counts[word_counts <= threshold])\n",
    "print('Total words: {}\\nTotal number of words whose occurence is less than 4: {}\\nDifference: {}'.format(x, y, x-y))\n",
    "words_less_than_threshold = word_counts[word_counts <= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [08:15<00:00, 5646.11it/s] \n"
     ]
    }
   ],
   "source": [
    "# Remove the words which have a count of less than 4 and replace them with the unique <UNK> symbol\n",
    "citation_word_features['neighboring_words'] = citation_word_features['neighboring_words'].progress_apply(\n",
    "    lambda x: [i if i not in words_less_than_threshold else '<UNK>' for i in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a mapping between word and index or vice versa\n",
    "words = pd.Series(Counter(chain.from_iterable(x for x in citation_word_features.neighboring_words))).index\n",
    "word2ind = {w: i for i, w in enumerate(words)}\n",
    "ind2words = {i: w for i, w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442905/442905 [00:35<00:00, 12404.84it/s]\n"
     ]
    }
   ],
   "source": [
    "word_embedding_matrix = np.zeros((len(word2ind), 300))\n",
    "for w in tqdm(word2ind):\n",
    "    index = word2ind[w]\n",
    "    word_embedding_matrix[index] = model.wv[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the word embedding for each word in the neighboring words, we sum the embeddings for each word together in neighboring words to get an embedding which represents the past 40 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [08:39<00:00, 5390.87it/s] \n"
     ]
    }
   ],
   "source": [
    "citation_word_features['words_embedding'] = citation_word_features['neighboring_words'].progress_apply(\n",
    "    lambda x: sum([word_embedding_matrix[word2ind[w]] for w in x])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the `citation_word_features` and `citation_tag_features`, so we can join them together to form `time_sequence_features` which would be fed later into the LSTM.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join time sequence features with the citations dataset\n",
    "time_sequence_features = pd.concat([citation_tag_features, citation_word_features.reset_index(drop=True)], keys=['id', 'citations'], axis=1)\n",
    "time_sequence_features = time_sequence_features.loc[:, ~time_sequence_features.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in time features are: (2800000, 42)\n"
     ]
    }
   ],
   "source": [
    "print('Total number of samples in time features are: {}'.format(time_sequence_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation_text = auxiliary_features.iloc[:,0]\n",
    "# auxiliary_features['citation_text'] = citation_text\n",
    "# auxiliary_features.drop('citation', axis=1, inplace=True)\n",
    "# auxiliary_features.rename({'citation_text': 'citation'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800000, 159)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join auxiliary features with the citations dataset\n",
    "citation_text_features.reset_index(drop=True, inplace=True)\n",
    "auxiliary_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "auxiliary_features = pd.concat([auxiliary_features, citation_text_features], keys=['id', 'citations'], axis=1)\n",
    "auxiliary_features = pd.concat([auxiliary_features['citations'], auxiliary_features['id']], axis=1)\n",
    "auxiliary_features = auxiliary_features.loc[:, ~auxiliary_features.columns.duplicated()]\n",
    "auxiliary_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with are duplicates\n",
    "auxiliary_features.drop(['neighboring_tags', 'characters'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del word_embedding_matrix\n",
    "del citation_word_features\n",
    "del citation_text_features\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sets for `auxiliary` and `time sequence` features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_with_features[['id', 'citations', 'label_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the time sequence features for the data\n",
    "time_sequence_features = pd.concat([time_sequence_features['id'], time_sequence_features['citations']], axis=1)\n",
    "time_sequence_features = pd.concat([time_sequence_features, data.reset_index(drop=True)], keys=['id', 'citations'], axis=1)\n",
    "time_sequence_features.columns = time_sequence_features.columns.droplevel(0)\n",
    "time_sequence_features = time_sequence_features.loc[:, ~time_sequence_features.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [01:21<00:00, 34148.91it/s]\n"
     ]
    }
   ],
   "source": [
    "time_sequence_features['words_embedding'] = time_sequence_features['words_embedding'].progress_apply(\n",
    "    lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [01:36<00:00, 29060.21it/s]\n"
     ]
    }
   ],
   "source": [
    "auxiliary_features['embedding'] = auxiliary_features['embedding'].progress_apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800000, 2800000)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_sequence_features), len(auxiliary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del book_features\n",
    "del journal_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training, testing and validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split is done into 80-10-10 ratio so that we have more training data to train on and have validation dataset to make sure that the model is working as anticipated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(auxiliary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels which will be split later\n",
    "y = auxiliary_features.loc[:, 'label_category'].astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a mask for auxiliary dataset to get all features except the one below\n",
    "column_mask_aux = ~auxiliary_features.columns.isin(['id', 'citations', 'label_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the columns of those auxiliary features and covert them into a list\n",
    "auxiliary = auxiliary_features.loc[:, column_mask_aux].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [02:00<00:00, 23243.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Convert them into numpy array (for Keras) and stack them (if needed) as suited for the model's format\n",
    "auxiliary = [np.array(auxiliary[i][0][0] + auxiliary[i][1:]) for i in tqdm(range(len(auxiliary)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a mask for time sequences features dataset to get all features except the one below\n",
    "cols = [col for col in time_sequence_features.columns if col not in ['id', 'citations', 'label_category', 'neighboring_words']]\n",
    "stripped_tsf = time_sequence_features[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = stripped_tsf.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_structure_time_features(time_features):\n",
    "    \"\"\"\n",
    "    Concatenate features which are numbers and lists together by checking the type:\n",
    "    \n",
    "    param: time_features: the features which are considered time sequence.\n",
    "    \"\"\"\n",
    "    feature_one = np.array([int(i) for i in time_features if isinstance(i, long)])\n",
    "    feature_two = np.array([i for i in time_features if isinstance(i, list)][0])\n",
    "    return np.array([feature_one, feature_two])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800000/2800000 [02:04<00:00, 22419.89it/s]\n"
     ]
    }
   ],
   "source": [
    "time = [make_structure_time_features(time[i]) for i in tqdm(range(len(time)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating PCA to 35 components since it should be equal to the size of the vector of the tags\n",
    "pca = PCA(n_components=35)\n",
    "\n",
    "def get_reduced_words_dimension(data):\n",
    "    \"\"\"\n",
    "    Get the aggregated dataset of words and tags which has the\n",
    "    same dimensionality using PCA.\n",
    "    \n",
    "    :param: data: data which needs to be aggregated.\n",
    "    \"\"\"\n",
    "    tags = [i for i, _ in data]\n",
    "    word_embeddings = [j for _,j in data]\n",
    "    pca.fit(word_embeddings)\n",
    "    \n",
    "    word_embeddings_pca = pca.transform(word_embeddings)\n",
    "    tags = np.array(tags)\n",
    "    return word_embeddings_pca, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA on all the sets of data to have the dimensions of the data to be the same\n",
    "word_embeddings_pca, tags = get_reduced_words_dimension(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pca = np.dstack((word_embeddings_pca, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2800000, 35), (2800000, 35), (2800000, 35, 2))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings_pca.shape, tags.shape, time_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "del time_sequence_features\n",
    "del auxiliary_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del data\n",
    "del word_embeddings_pca\n",
    "del tags\n",
    "del stripped_tsf\n",
    "del column_mask_aux\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM/Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_nn(features_aux, features_time, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Generator to create batches of data so that processing is easy.\n",
    "    \n",
    "    :param: features: the features of the model.\n",
    "    :param: labels: the labels of the model.\n",
    "    :param: batch_size: the size of the batch\n",
    "    \"\"\"\n",
    "    # Create empty arrays to contain batch of features and labels\n",
    "    batch_features_aux = np.zeros((batch_size, 453))\n",
    "    batch_features_time =  np.zeros((batch_size, 35, 2))\n",
    "    batch_labels = np.zeros((batch_size, 3))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index = np.random.choice(len(features_aux), 1)[0]\n",
    "            batch_features_aux[i] = features_aux[index]\n",
    "            batch_features_time[i] = features_time[index]\n",
    "            batch_labels[i] = labels[index]\n",
    "        yield [batch_features_time, np.asarray(batch_features_aux)], batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    import math\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model():\n",
    "    \"\"\"\n",
    "    Model for classifying whether a citation is scientific or not.\n",
    "    \"\"\"\n",
    "    main_input = Input(shape=(35, 2), name='time_input')\n",
    "    lstm_out = LSTM(64)(main_input)\n",
    "\n",
    "    auxiliary_input = Input(shape=(453,), name='aux_input') ## 454 without citation type, 476 with citation type\n",
    "    # Converging the auxiliary input with the LSTM output\n",
    "    x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "    # 4 fully connected layer\n",
    "    x = Dense(256, activation='selu')(x)\n",
    "    x = Dense(128, activation='selu')(x)\n",
    "    x = Dense(128, activation='selu')(x)\n",
    "    x = Dense(64, activation='selu')(x)\n",
    "\n",
    "    main_output = Dense(3, activation='softmax', name='main_output')(x)\n",
    "    model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output])\n",
    "    \n",
    "    opt = Adam(0.001)\n",
    "    model.compile(\n",
    "        optimizer=opt, loss={'main_output': 'categorical_crossentropy'},\n",
    "        loss_weights={'main_output': 1.}, metrics=['acc']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch/harshdee/tensorflow_cpu/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3313: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "time_input (InputLayer)         (None, 35, 2)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 64)           17152       time_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          (None, 453)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 517)          0           lstm_2[0][0]                     \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          132608      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          16512       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           8256        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 3)            195         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 207,619\n",
      "Trainable params: 207,619\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the classification model\n",
    "model = classification_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `ReduceLRonPlateau` so that the model does not overshoot the optimal minimum point and hence by default we start with a learning rate of 0.01 but as soon as the accuracy stop increasing the learning rate does not change which helps us converge better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert auxiliary into numpy array for indexing\n",
    "auxiliary = np.asarray(auxiliary)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_indices, x_test_indices, y_train_indices, y_test_indices = train_test_split(\n",
    "    range(auxiliary.shape[0]), range(y.shape[0]), train_size=0.9, stratify=y, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_train = auxiliary[x_train_indices]\n",
    "time_train = time_pca[x_train_indices]\n",
    "y_train = np.eye(3)[y[x_train_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_test = auxiliary[x_test_indices]\n",
    "time_test = time_pca[x_test_indices]\n",
    "y_test = y[x_test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model with epochs: 30\n",
      "Epoch 1/30\n",
      "7406/9843 [=====================>........] - ETA: 2:53 - loss: 1.2430 - acc: 0.8103"
     ]
    }
   ],
   "source": [
    "# predictions = []\n",
    "# for index, (train_indices, val_indices) in enumerate(skf.split(auxiliary, y)):\n",
    "#     aux_train, aux_val = auxiliary[train_indices], auxiliary[val_indices]\n",
    "#     time_train, time_val = time_pca[train_indices], time_pca[val_indices]\n",
    "#     y_train = np.eye(4)[y[train_indices]]\n",
    "#     y_val = y[val_indices]\n",
    "    \n",
    "BATCH_SIZE = 256\n",
    "print('Running model with epochs: {}'.format(EPOCHS))\n",
    "\n",
    "model = None\n",
    "model = classification_model()\n",
    "training_generator = generator_nn(aux_train, time_train, y_train, BATCH_SIZE)\n",
    "\n",
    "history_callback = model.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=len(x_train_indices) // 256,\n",
    "    epochs=EPOCHS, verbose=1, shuffle=True, callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model with epochs: 5\n",
    "# Epoch 1/5\n",
    "# 11601/11601 [==============================] - 421s 36ms/step - loss: 0.7328 - acc: 0.7955\n",
    "# Epoch 2/5\n",
    "# 11601/11601 [==============================] - 413s 36ms/step - loss: 0.3311 - acc: 0.8823\n",
    "# Epoch 3/5\n",
    "# 11601/11601 [==============================] - 413s 36ms/step - loss: 0.2957 - acc: 0.8946\n",
    "# Epoch 4/5\n",
    "# 11601/11601 [==============================] - 406s 35ms/step - loss: 0.2777 - acc: 0.9024\n",
    "# Epoch 5/5\n",
    "# 11601/11601 [==============================] - 410s 35ms/step - loss: 0.2617 - acc: 0.9085\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history_callback.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/dlabdata1/harshdee/results/citation_model_loss_{}.json'.format(EPOCHS), 'w')\n",
    "f.write(str(history_dict))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_for_folds = model.predict([time_test, aux_test])\n",
    "y_pred = np.argmax(prediction_for_folds, axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Neural network model for epochs {}: {}\".format(EPOCHS, accuracy))\n",
    "\n",
    "res = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "res.index = ['book', 'journal', 'web']\n",
    "res.columns = ['book', 'journal', 'web']\n",
    "res['accuracy'] = accuracy\n",
    "res.to_csv('/dlabdata1/harshdee/results/citation_model_result_{}.csv'.format(EPOCHS))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/dlabdata1/harshdee/results/citation_model_epochs_{}.h5'.format(EPOCHS))\n",
    "json_string = model.to_json()\n",
    "with open(\"/dlabdata1/harshdee/results/citation_model_epochs_{}.json\".format(EPOCHS), \"w\") as json_file:\n",
    "    json_file.write(json_string)\n",
    "\n",
    "print('\\n\\nDone with the prediction and saving model with epochs: {}\\n'.format(EPOCHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
